# Big Transfer

- 谷歌发文介绍了其BigTransfer（BiT），称其为目前最先进的预训练模型，在分类问题中仅需要每个类少量几个样本即可达到极其优秀的性能。
- 事实上，在ImageNet预训练的ResNet50系列模型是当前的工业标准，用于提取图像特征。在谷歌在论文 BigTransfer (BiT) 中分享的模型则可以轻松打败ResNet50，尽管数据量很少。
- 在TFHub中谷歌已经发布了在ImageNet数据集和ImageNet-21K数据集上的模型，这些模型复杂度从ResNet50 到ResNet152x4（152层深，ResNet50的4x宽），可以根据自己的硬件选择更适合的高精度模型。

- 训练阶段
  - 1）更多的数据，最好的模型是再多增加一些训练数据的模型；
  - 2）更大的架构，数据够多的时候，模型也需要相应的更大的架构
  - 3）更长的训练时间，在更大数据集上的预训练需要更多的训练轮数
  - 4）使用GroupNorm 和 Weight Standardisation
     - 将GroupNorm与Weight Standardisation 结合使用，而不是BatchNorm。 由于模型很大，因此每个加速器（例如GPU或TPU芯片）只能容纳几张图像，当每个加速器上的图像数量太少时，BatchNorm的性能会变差。
     - GroupNorm没有此问题，但不能很好地扩展到较大的批大小。 而将GroupNom与Weight Standardization结合使用时，就可以很好地扩展到大批量，甚至优于BatchNorm

- 微调阶段
  - 使用BiT微调，即使是在每类样本数很少的时候也能获得叫让人满意的精度。另外谷歌还设计了一套启发式超参数配置机制BiT-HyperRule，无需昂贵的参数搜索就可以在大多数任务中得到相当不错的性能。
  - BiT-HyperRule 是通过数据集的统计信息和特点，给出一套行之有效的参数配置。
  - 在BiT-HyperRule中，使用SGD，初始学习率为0.003，动量为0.9，批大小为512。
  - 微调过程中，在训练到总步数的30%，60％和90％时，学习率降低10倍。
  - 数据预处理时，对图像进行大小调整，随机裁剪，然后进行随机水平翻转。
  - 除了那些破坏标签语义的动作，对所有任务都做随机裁剪和水平翻转。例如，不对计数任务进行随机裁剪，也不对要预测物体方向的任务进行随机水平翻转