# StyleGAN Manipulation

## StyleGAN-Encoder
- StyleGAN建立的其实是（18,512）维的向量到（1024,1024,3）维的向量的映射关系，而后者具有一些属性，譬如年龄、性别、表情等，如果我们能探究出后者属性的变化在前者（生成域）上对应变化的关系，那么我们就能够对生成人脸的属性进行编辑和操作
- 变化关系可以用一个方向向量e来表示，它与dlatent的维度是一致的。对于求e,较简单的方法是，每次取两个sample，用它们dlatent的差值除以label的差值，就得到了一个估测值，然后多次重复这一过程，将所有的方向向量累加起来并求平均值，就得到了估计的方向向量。

![](http://www.seeprettyface.com/images/note/direction1.png)

- 首先使用训练好的styleGAN的生成器，输入不同的z，生成得到人脸图片和中间向量，对这些人脸图片进行性别标记，每一张图片的中间向量和性别标记则形成了这个特征的训练集。之后采用分类器，如逻辑回归或其他，对该数据集进行训练，逻辑回归方法中的参数，即为性别种类的分界线，该参数数量和中间向量的维度一致，该参数即为性别特征的单位。工作中介绍到，对某一种特征，需要的种类图片有100张即可以达到80%的分类准确率。如果某种特征有多个标签，需要尝试将多类别变成线性关系。

## GANSpace
- NIPS 2020
- 首个无监督的通用方法，用于寻找隐空间中可解释的漂移方向，无监督可以节约大量数据标注成本，同时能够找到监督方法找不到的漂移方向
- 用PCA的方法对GAN空间做分析，发现一些可编辑可控的特征。
- PCA的目的是把原本N维度的数据，放到N维空间中，用k（小于等于N）个正交的N维单位向量表示它，使它投影过去之后得到K维（坐标），并且协方差矩阵是一个对角阵（相当于K维互相正交），再根据投影过去之后的坐标排序（向量模尽可能大）找出方差最大的方向

![](https://pic4.zhimg.com/80/v2-c682ea2018efc8c66d77cc542be50d9f_1440w.jpg)

- 基于主成分分析（PCA）在潜在空间或特征空间中识别重要的潜在方向。然后证明了大量的可解释控制可以通过沿主方向的逐层扰动来定义。
- 越大的主成分，控制的越宏观
- 利用PCA对W空间进行分析，发现
    - 几何结构和视点的大规模变化仅限于前20个主成分（v0-v20）
    - PCA还显示StyleGanV2的潜在分布P（w）具有相对简单的结构：主坐标几乎是具有非高斯单峰分布的独立变量。我们还发现，前100个主成分足以描述整体图像外观；剩下的412个维度控制着外观上细微但可察觉的变化
- 主成分可能包含严重的特征纠缠，如：将汽车调整为更具“运动性”会导致更具“开放道路”背景，而更具“家庭”背景的汽车则出现在树林或城市街道上；“皱纹”编辑会使成年人的脸变老并增加皱纹，但对儿童的脸没有显著影响

![](https://img-blog.csdnimg.cn/0bd0803650bf49bba7ed4b43d5892df4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bmz5LuA5LmI6Zi_,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

- 上图表示，利用PCA可以发现从宏观到微观的特征，越主要的成分越宏观。相比随机方向或正则方向（本质相同，因为正则方向各向同性），随机方向更加杂乱

## InTerFaceGAN
- CVPR 2020
- 本文首先对GAN模型的潜在空间Z中出现的语义属性进行了严格的分析，然后构建了利用潜在编码z中的语义进行面部属性编辑操纵的pipeline。
- 本文将每种二分类特征看作一个超平面，超平面两侧是两种特征种类，离超平面的距离表现了二分类特征的“浓度”，超平面的法向量即为编辑方向。不同种类特征的超平面不一定是互相垂直的，所以试图单独编辑某种特征时，往往会导致另一种特征也会被修改。例如戴眼镜和年龄大的关系比较强，编辑年龄更大时可能会导致出现眼镜。在编辑年龄法向量时，可以计算该单位向量在戴眼镜特征法向量垂直方向上的投影，从而可以获得不被影响的方向向量，在该方向上编辑即可，这种操作在文中被称为conditional manipulation。但是需要知道当前特征向量和哪些特征向量非常相关，并且将强相关的特征均计算其超平面。

## StyleSpace
- CVPR 2021
- 一篇基于隐空间构造的解耦文章，其思路是构造了一个Style隐空间，认为在该空间上的编码具有更好的解耦效果。
- 目前的风格迁移任务通常需要成对样本，并且需要较多的监督信息；目前方法的单个属性通常与其他属性存在纠缠，并且其作用是非局部的。本文分析了隐空间对于图像解耦生成效果的影响；提出了一种基于样式编码通道的属性检测即可视化方法；提出了一种新的解耦评价指标属性依赖（Attribute Dependency）。

![](https://pic4.zhimg.com/80/v2-17646feed5dfcbcfdb02cbed639edcab_1440w.jpg)

- 上图中表示了StyleGAN2生成器一个主要网络层的隐空间构造和使用方法，其他主要层类似，首先使用全连接层将Z空间映射到W空间/W+空间，实际上这一步的操作是一样的。然后，在StyleGAN2的生成器中，一个主要网络层由三个卷积层组成，其中，两个卷积层用于特征图合成，一个特征图送入下一个主要网络层，另一个特征图则再由第三个卷积层（tRGB）映射成RGB图像，用于上图右侧的级联处理。因此，一个主要网络层将会使用到三个style参数，也就是图中的 $S1$， $S2$ 和 $S_{tRGB}$，他们通过对卷积核权重进行调整影响生成特征图的方差，其的构造均是从W空间/W+空间经仿射变换得到的.
- 为了评估不同隐空间的属性分离程度，作者在CelebA上训练了40个二元属性检测器，来检测人脸属性，然后使用StyleGAN2生成图像，计算这些图像包含的属性与不同隐空间之间的DCI，用于评估不同隐空间控制属性的效果。因此得出结论StyleGAN的style space对于解耦来讲是具有天然优势的。

![](https://pic3.zhimg.com/80/v2-f5eb0ce698166d61a9f7d342738329c6_1440w.jpg)

- 经过上一步的分析，作者得出结论，即样式空间具有最高的线性可分性，在该空间上进行解耦实验的效果相对而言更好。为了挖掘样式空间对不同属性具体控制情况，实现属性与样式编码的绑定，作者预训练了一个语义检测网络来探测不同语义特征的区域，获得相关的语义mask，然后，计算生成图像与不同分辨率，不同通道的样式编码之间的梯度，获得一个梯度热图，假如梯度热图与某一属性的语义mask重合度很高，那就认为这个通道的样式编码与这个属性具有强相关性。
- 解耦评价指标——属性依赖Attribute Dependency (AD)：属性依赖指标的思想是，对于某一具体属性，假如已经检测出控制该属性的风格编码，那么可以对该属性进行修改，观测其他属性的变化情况，进而评估不同属性的分离程度。

## StyleFlow
- ArXiv 2020.08
- 本文作者在纠缠隐空间(latent space)的条件下，研究了**属性约束采样**和**属性控制编辑**两个子问题。提出一个简单、有效、鲁棒的解决方法：StyleFlow

![](https://pic4.zhimg.com/80/v2-d4837688f5222ec360dea7ca43180ef7_1440w.png)

- 本文的工作主要着重于以下两个方面的研究：（1）属性约束采样，目的是对满足用户指定属性的各种图像集进行采样；（2）属性可控编辑，目的是对用户指定的具有目标属性指定的特定图像依次改变。


## Reference
- [1 Manipulation](https://blog.csdn.net/ygfrancois/article/details/114021752)
- [2 GANSpace](https://zhuanlan.zhihu.com/p/391433134)
- [3 GANSpace](https://blog.csdn.net/qq_41433002/article/details/121120828)
- [4 InterFaceGAN](https://zhuanlan.zhihu.com/p/140553228?ivk_sa=1024320u)
- [5 StyleSpace](https://zhuanlan.zhihu.com/p/455806847)
- [6 StyleFlow](https://blog.csdn.net/Mark_2018/article/details/112923516?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1.pc_relevant_default&spm=1001.2101.3001.4242.2&utm_relevant_index=4)