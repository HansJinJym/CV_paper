# StyleGAN 相关技术梳理

## 图像生成
### StyleGAN
- 基于样式的生成网络，改进传统网络（ProGAN）的问题
- 创新点：
    - 网络：W空间，特征解缠（映射网络8个全连接），AdaLIn仿射（每个w仿射出两个值用于归一化，修改生成图像内容），常值输入（避免输入选取值不当的问题），随机噪声（保证多样化）
    - 训练：Style mix（融合两个图像，内容+样式，生成的图像多样化），w截断（对于有些特征样本较少，对w去平均并整体压缩距离）
- w空间特征解缠原理
    - 如果仅使用输入向量来控制视觉特征，能力是非常有限的，因此它必须遵循训练数据的概率密度。例如，如果黑头发的人的图像在数据集中更常见，那么更多的输入值将会被映射到该特征上。因此，该模型无法将部分输入（向量中的元素）映射到特征上，这就会造成特征纠缠。然而，通过使用另一个神经网络，该模型可以生成一个不必遵循训练数据分布的向量，并且可以减少特征之间的相关性。
### StyleGAN2
- 改进水滴伪影问题，修改AdaLIN（去掉均值操作，但是会导致style mix时某一特征放大程度过大），引入调制解调器（改成对权重做操作），噪声移到生成block外
### StyleGAN3
- 改进特征停滞问题（通过采样定理、傅立叶特征等方式）
### SWAGAN
- 图像域的操作改为频率域，直接解决了高频问题
- 更少、更快的计算量
### MobileStyleGAN
- 利用小波、深度可分离卷积、蒸馏训练

## 动漫化
### CycleGAN
- 两个G两个D，解决风格迁移图像一一对应问题
### U-GAT-IT
- CycleGAN基础上，添加AdaLIN和attention

## 逆映射
### pSp
- 训练金字塔编码器（特征金字塔提取三个尺度特征，通过FCN映射成w），引入多种loss，将图像映射至潜码
- 传统方法主要是随机选w，生成图像，不断迭代更新，时间算力长，效果不好
### e4e
- 原理类似

## 属性编辑
### GANSpace
- 利用PCA（主成分分析）找到StyleGAN的潜码的可解释移动方向
### InterFaceGAN
- 通过线性变化潜码，学习一种解耦表征
### StyleSpace
- S空间解藕
### StyleFlow
### HiSD
- 层次性解藕，融合，达到编辑目的
### SeFa
- 对模型参数闭环求解
### StyleCLIP
- 语义控制编辑

## 图像动作驱动
### First-Order-Motion
- 通过关键点，计算变换图和掩盖图，送入解码器inpainting